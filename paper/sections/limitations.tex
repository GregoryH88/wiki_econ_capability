\section{Limitations and Future Work}
The results we have presented show that contributions -- and the value they provide to the collective good -- can be disentangled, with the {bi-partite network random walker} model. However, these results suffer from a number of limitations, which call for further work and testing.

In our model, the value of contributions is only inferred from the binary matrix of contributions. 

less is more

%It remains unclear why the correlation of the method with the grand-truth for editors increases as a convex function of time (see Figure \ref{fig:rhotime} lower panel). We have proposed that it could be the result of the shape of the input matrix $\mathbf{M}$ : usually categories have factors more editors than articles and therefore more information accumulated over time is needed to adequately rank the editors. This hypothesis could be tested further by screening more Wikipedia categories according to a broader ratio of editors and articles. 

According to the original philosophy of the reflection method \cite{hidalgo2007}, the capabilities of producing entities (e.g., countries) that constrain the production are not observable. We believe this is feasible in the case open collaboration. We can for instance identify what an editor do best to improve an article, among the five metrics (ratio of mark-up to readable text, number of headings, article length, citations per article length, and outgoing intrawiki links) we have used to assess the quality of an article.

We believe there are two further directions to improve our results. First we have followed the philosophy of the reflection method and we have used rankings by defaults. However, the bi-partite network random walker method provides absolute values, which might have a meaning in the context of open collaboration. Second, we took the very simplest information for the input matrix $\mathbf{M}$ (i.e. whether an editor has modified an article). We wonder how the performance of the method might change if richer information is incorporated in the matrix (e.g., number of edits). Would it improve performance or on the contrary reduce it ?

- Improve search algorithm for calibration of $\alpha$ and $\beta$. For the time being we are performing grid search, which is less than optimal.

- Although the results are robust given the poor input (whether an editor has contributed to an article or not) Change the input : what happens if a richer input 


- we shall explore ways to improve the correlation and the predictive power of the algorithm. Let's consider that we are able to successfully calibrate $\alpha$ and $\beta$ and we know how they are likely to evolve as a category of articles gets further enriched, then as editors contribute, it will be possible to know how they have created added value to the collective project.


%We only look at the ranking not at the real quality/expertise values ? Can we learn more the real values about the gap between articles/editors ?

%{\bf [initially in discussion but we have not figure to support this point]} : When we use $\mathbf{M}$ %which is a binary version of $\mathbf{\hat{M}}$ we achieve better results. Knowing that editor touched an article, is more informative than knowing the edit count.  Wikipedia even acknowledges its {\it editcountitis, Compteurd√©dite} with the essay \cite{editcountitis}Wikipedia has never been explicitly gamified, but some editors are immediately attracted to tracking their performance. This leaves us with an overused, and perverse-incentive metric. In fact what we have shown is that edit truly is meaningless when it comes to predicting editor investment and quality. This is a departure from the economics domain, where the best fits for GDP are only in the positive / positive $\alpha$-$\beta$ quadrant.In the cases where maximizing $\alpha$, $\beta$ solution spaces are linear we get a kind of single variable characteristic of a category. 


