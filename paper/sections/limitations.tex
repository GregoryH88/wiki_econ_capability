\section{Limitations and Future Work}
The results we have presented in this paper show that contributions -- and the value they provide to the collective good -- can be well disentangled with the {bi-partite network random walker} model. However, these results suffer from a number of limitations, which call for further work and testing. 

%It remains unclear why the correlation of the method with the grand-truth for editors increases as a convex function of time (see Figure \ref{fig:rhotime} lower panel). We have proposed that it could be the result of the shape of the input matrix $\mathbf{M}$ : usually categories have factors more editors than articles and therefore more information accumulated over time is needed to adequately rank the editors. This hypothesis could be tested further by screening more Wikipedia categories according to a broader ratio of editors and articles. 

According to the original philosophy of the method of reflections \cite{hidalgo2007}, an additional node type reflecting {\it capabilities} should connect producing and produced entities. In the current approach, capabilities are implicit in the model, mainly because they are not observable. In the context of Wikipedia and open collaboration, incorporating capabilities would be more feasible. We can for instance identify what an editor do best to improve an article, among the five metrics (ratio of mark-up to readable text, number of headings, article length, citations per article length, and outgoing intrawiki links) we have used to assess the quality of an article.

We believe there are two further directions to improve our results. First, we have followed the philosophy of the method of reflections that aims at ranking countries in the world economy. However, the bi-partite network random walker method provides absolute values, which might have a meaning in the context of open collaboration. In future work, we would like to understand further these absolute values. Second, we took the very simplest information for the input matrix $\mathbf{M}$ (i.e. whether an editor has modified a given article, or not). We wonder how the performance of the method might change if richer information is incorporated in the matrix (e.g., number of edits, number of bytes changes). Two exclusive hypotheses could be tested: either the model fits better with richer information, or on the contrary, the model is not as good. In the latter case, we would face a {\it less is more} scenario, which would require elucidating why less rich information accounts better for reality. Or conversely, it could help further understand what ground-truth metrics actually contain richer information, and hence, help reverse engineer most relevant direct measures of editor expertise and article quality.

As it stands, our method for finding the optimizing pair of control parameters $(\alpha^*,\beta^*)$ for the {\it bi-partite network random walker} model is a grid search, because gradient-based optimizers do not handle the singularities that the model produces. Given that computer time required by grid-search grows at the square of the problem (e.g. the size of a category), more work is needed to improve the efficiency of the optimizing algorithm for calibration of $\alpha$ and $\beta$. We shall also fix the method to obtain more smooth optimization spaces.

%A future direction is to explore ways to improve the correlation and the predictive power of the algorithm. At the moment we must calibrate $alpha$ and $beta$ for a category before being able to make predictions. If we could relate $alpha$ and $beta$ to another known parameter then one could start making predictions about the performance of editors and articles.

%We only look at the ranking not at the real quality/expertise values ? Can we learn more the real values about the gap between articles/editors ?

%{\bf [initially in discussion but we have not figure to support this point]} : When we use $\mathbf{M}$ %which is a binary version of $\mathbf{\hat{M}}$ we achieve better results. Knowing that editor touched an article, is more informative than knowing the edit count.  Wikipedia even acknowledges its {\it editcountitis, Compteurd√©dite} with the essay \cite{editcountitis}Wikipedia has never been explicitly gamified, but some editors are immediately attracted to tracking their performance. This leaves us with an overused, and perverse-incentive metric. In fact what we have shown is that edit truly is meaningless when it comes to predicting editor investment and quality. This is a departure from the economics domain, where the best fits for GDP are only in the positive / positive $\alpha$-$\beta$ quadrant.In the cases where maximizing $\alpha$, $\beta$ solution spaces are linear we get a kind of single variable characteristic of a category. 