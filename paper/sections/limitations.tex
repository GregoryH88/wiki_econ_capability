\section{Limitations and Future Work}
The results we have presented show that contributions -- and the value they provide to the collective good -- can be disentangled, with the {bi-partite network random walker} model. However, these results suffer from a number of limitations, which call for further work and testing.

%It remains unclear why the correlation of the method with the grand-truth for editors increases as a convex function of time (see Figure \ref{fig:rhotime} lower panel). We have proposed that it could be the result of the shape of the input matrix $\mathbf{M}$ : usually categories have factors more editors than articles and therefore more information accumulated over time is needed to adequately rank the editors. This hypothesis could be tested further by screening more Wikipedia categories according to a broader ratio of editors and articles. 

According to the original philosophy of the reflection method \cite{hidalgo2007}, the capabilities of producing entities (e.g., countries) that constrain the production are not observable. We believe this is feasible in the case open collaboration. We can for instance identify what an editor do best to improve an article, among the five metrics (ratio of mark-up to readable text, number of headings, article length, citations per article length, and outgoing intrawiki links) we have used to assess the quality of an article.

We believe there are two further directions to improve our results. First we have followed the philosophy of the method of reflections and we have used rankings by defaults. However, the bi-partite network random walker method provides absolute values, which might have a meaning in the context of open collaboration. Second, we took the very simplest information for the input matrix $\mathbf{M}$ (i.e. whether an editor has modified an article). We wonder how the performance of the method might change if richer information is incorporated in the matrix (e.g., number of edits). In the economics domain previous research has described using a binary matrix as computing GDP per capita, whereas using the full production data computes GDP. Our preliminary impressions using edit counts rather than the binary "touches" model showed worse correlations, but we did not launch a full investigation into this matter.

As it stands our method for finding the optimizing pair $(\alpha,\beta)$ is a grid search, because gradient-based optimizers do not handle a singularity that the model produces. There need for improvement search algorithm for calibration of $\alpha$ and $\beta$.


A future direction is to explore ways to improve the correlation and the predictive power of the algorithm. At the moment we must calibrate $alpha$ and $beta$ for a category before being able to make predictions. If we could relate $alpha$ and $beta$ to another known parameter then one could start making predictions about the performance of editors and articles.

%We only look at the ranking not at the real quality/expertise values ? Can we learn more the real values about the gap between articles/editors ?

%{\bf [initially in discussion but we have not figure to support this point]} : When we use $\mathbf{M}$ %which is a binary version of $\mathbf{\hat{M}}$ we achieve better results. Knowing that editor touched an article, is more informative than knowing the edit count.  Wikipedia even acknowledges its {\it editcountitis, Compteurd√©dite} with the essay \cite{editcountitis}Wikipedia has never been explicitly gamified, but some editors are immediately attracted to tracking their performance. This leaves us with an overused, and perverse-incentive metric. In fact what we have shown is that edit truly is meaningless when it comes to predicting editor investment and quality. This is a departure from the economics domain, where the best fits for GDP are only in the positive / positive $\alpha$-$\beta$ quadrant.In the cases where maximizing $\alpha$, $\beta$ solution spaces are linear we get a kind of single variable characteristic of a category. 