\section{Related Work}
%You can do some more intro here if you really want but i don't think its necessary.
%The problem of ranking entities and their respective production is relevant to the flourishing production of knowledge on the Web, and is directly related to two outstanding problems, which have been previously debated. First, how do we gauge the quality (resp. reliability) of blog posts, book reviews (e.g., on Amazon), or restaurant reviews (e.g., on Yelp) ?  Second,  how to grant editing and administrative privileges on community networks (e.g., Slashdot) and on online collaborative platforms (e.g. Wikipedia) \cite{halfaker2013}. 

%Some websites (e.g., ebay? Amazon?) allow rate the rater. This approach is similar to the very first steps of the reflexivity method ! \cite{citation needed.}

The well known PageRank algorithm, developed to rank web pages, is based only on the number of times a page is linked to by other pages. \cite{page1999pagerank}. This model considers only one type of node: a webpage.  Our problem differs in that we want to rank two types of nodes: editors and articles. This generalization has been considered by a growing stream of literature that aims to see economies as a network of two node types. Entities (e.g., firms, countries) and exported products are considered as an inroad to uncover an entity's capabilities \cite{hidalgo2007}. Capabilities cannot be observed, and the approach assumes that products are a proxy of each entity's capabilities. As result, if they have overlapping sets of capabilities, entities may compete for selling similar products. From an economic perspective, the way entities compete on similar - or dissimilar - market segments allows comparing the structure, and arguably, the competitiveness an entity's economy. 

The relation between products and entities can be modelled by the so-called {\it bi-partite networks} with remarkable properties \cite{hidalgo2009} that we leverage in this paper, to better understand how content quality and editors' expertise relate in open collaboration. The core idea is to introduce a reflexive metric, which helps understand the value of entities (i.e., {\it fitness}) from the products they sell, as well as the {\it ubiquity} of a product from the number of entities, which have the capabilities to produce and sell it. This is the basis of an iterative method called {\it method of reflections}, in which at each iteration the value of an entity can be evaluated from the averaged ubiquities of the products it exported at the previous step. For this we need to determine the ubiquities of the products in question, which is in turn evaluated from the averaged fitnesses of the entities that exported it. The reflexivity method is explained in more detail in the Method section as it relates to Wikipedia articles and editors. In its initial formulation \cite{hidalgo2009}, the algorithm suffers a number of pitfalls, among which the most important one is its convergence to a fixed point. Indeed, after a sufficient number of iterations, all entities have the same fitness, and all products have the same ubiquity, while the algorithm should on the contrary further discriminate entities and products as the number of iterations increases. 

Several alternative methods have been proposed to avoid the fixed-point problem of the algorithm \cite{tacchella2012new, cristelli2012competitors, tacchella2013economic, cristelli2013measuring}. In particular, Caldarelli et al. \cite{caldarelli2012network} have explained in details the nature of the problem and proposed an alternative method, based on biased Markov chains, which solve the fixed-point problem on the on hand, and further understand the nature of the bi-partite network structure on the other. 
