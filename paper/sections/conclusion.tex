Endogenous expertise acquisition by editors and quality of Wikipedia articles is a critical problem to overcome in order to understand how people, as individuals, contribute to the achievement of high quality knowledge as public good and how articles greatly benefit from their iterative inputs. For 12 categories of Wikipedia articles, we have identified and calibrated metrics from a {bi-partite network random walker} model. These metrics quantify how editors expertise and articles quality is derived from the variety of inputs made by individuals over time. These metrics give direct insights on how some categories of Wikipedia articles mainly benefit from either a broad set of small inputs by lay-persons, or on the contrary, from a few ``experts" in the field. They also tell whether editors expertise is rather achieved through contributions to a broad set of articles, or by concentrating on a few high level articles. While this method suffers limitations, a similar approach can be extended for better understanding how contributions are valued in open collaboration. Similarly, it could applied to a broad variety of situations, such as social coding (e.g., Github) , or collaborative rating (e.g., Amazon or Yelp reviews), to help understand to origins of quality and reliability, which is often highly recognized and valued in open collaboration.
