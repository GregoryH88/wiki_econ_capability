\section{Discussion}

One of the brightest results here is that in using the method described for predicting world economies by GDP, we not only can predict Wikipedia editor and article rankings, but outperform the original application. Whereas in \cite{caldarelli2012network} they achieve a maximum correlation of 0.4, that is on the lower end of our results. 

A theory to explain this behaviour goes back to the original motivation in creating this method, that of trying to find "capabilities". In Economics there are circumstantial factors that influence a countries capabilities, e.g. Geography or Politics. However in Wikipedia all outputs are only due to the editors' true underlying capabilities. There are no commodities and articles have no intrinsic value until they are written. If this explained why our correlations were higher, it might also be true for other online collaboration sites, where users operate in a within a greater meritocracy.

Yet viewing result from the other side is more important, as much as we are uncovering hidden capability of editors, we can better predict article quality. Arguably this is more substantial because it answers the open source question, of being able to judge qualitative, subjective natural language files, even if we can't compile and benchmark them.   

In Wikipedia there has been discussion about the importance of super-users who represent a small fraction of editors but contribute a majority of content. \cite{website:wikinewsreporter}. It is possible now to take $\alpha$ as a measure of importance of superuser contributions. Since different categories we correlate more highly for different ranges of $\alpha$ it is possible to compare the success of super-users in different categories. Moreover we can also find which categories are most closely modelled by low or negative values of $\alpha$ which represents better articles are made by less fit editors. Ways to determine this pheonomena could be two or more power users fighting over a page can leave it worse than not being touched at all. A concern raised in \cite{halfaker2013}.  
 
 
When we use $\mathbf{M}$ which is a binary version of $\mathbf{\hat{M}}$ we achieve better results. Knowing that editor touched an article, is more informative than knowing the edit count.  Wikipedia even acknowledges its {\it editcountitis, Compteurd√©dite} with the essay \cite{editcountitis}
Wikipedia has never been explicitly gamified, but some editors are immediately attracted to tracking their performance. This leaves us with an overused, and perverse-incentive metric. In fact what we have shown is that edit truly is meaningless when it comes to predicting editor investment and quality.



This is a departure from the economics domain, where the best fits for GDP are only in the positive / positive $\alpha$-$\beta$ quadrant.
In the cases where maximizing $\alpha$, $\beta$ solution spaces are linear we get a kind of single variable characteristic of a category. 

