\section{Discussion}
Building on the method of reflections previously used for global economic networks of production, we have applied and tested the {\it bi-partite network random walker} model in the context of Wikipedia open collaboration. Our results show that the model accounts well for the quality of articles $\rho_a$ around $0.64$ and for the expertise of contributors $\rho_e$ around $0.72$, even though the actual quality and expertise metrics are very rough. Moreover, the evolution of $\rho_e$ and $\rho_a$ of categories under editing, show astonishing stability. In particular, the adequacy of the model to article quality is very high early on thereafter being stationary, suggesting that the model can quickly asses the quality of articles. For editors expertise, the adequacy increases steadily as categories get further developed. 

This difference might be due to the roughness of the actual metrics for editors $\bar{w}_e$, expressed in labor-hours, compared to the quality of $\bar{w}_a$, which is an aggregate measure of five precise quality metrics. Nevertheless, the correlation of editor ranking with $\bar{w}_e$ increases: $\rho_e$ exhibits a convex increase over time, suggesting that it takes time (i.e., lots of edits) to capture well the expertise of editors as well as for editors. This is striking because the method is reflexive and the same information is incorporated on both dimensions from the input matrix $\mathbf{M}$. While we have no definitive answer, we interpret this result in the following way: from Figure \ref{fig:triangle_matrix}, we see that there are usually more editors than articles for a category. This means that the probability for an article to get contributions early on is higher than the probability to find editors who have contributed to a lot of articles early. In other words, it takes more time to rightly rank editors because there are more compared to the number of articles in a given category.

%We have also found $\alpha \approx 0$ for all categories, reflecting the positive influence of the number of articles edited on editors expertise. This fact tells actually a lot about the model.  The actual metric for editors expertise takes only into consideration the labor hours \cite{geiger2013}, and the more time is spent editing a category, the more likely the editor will have modified a large quantity of articles. The value of $\alpha$ can therefore be explained entirely by the nature of the ground-truth metric. Although it would require further testing with a broad variety of metrics, it seems that the {bi-partite network random walker} model can {\it tune} to whatever ground-truth metric used for calibration. In other words, the values of $\alpha$ and $\beta$ only reflect the structure of value creation in open collaboration, {\it given} the chosen ground-truth metrics. 

We have also found $\alpha \approx 0$ for all categories, reflecting the linear influence of the number of articles edited on editors expertise. The interpretation for this is that an editor is generally as good as the number of articles they have edited. When we substitute "good" with our actual metric, labor-hours, we'd find that labor-hours are directly related to the number of articles edited. So our result means that articles-touched is a reasonable proxy for labor-hours. This suggest that there are no diminishing returns on investing hours and touching new articles.

Finally we find that whether editor ubiquity is a measure of article quality or not is category dependent. With examples from both ends of the spectrum we find footing to propose to take our $\beta$ coefficient to be a proxy for the "collaborativeness," of a category. Consider the highest $\beta$ found, on category {\it Sexual acts}. We chose to include this category because it could be considered taboo or perverse to edit these articles.  This category has the least gain from better editors touching more articles. An explanation could because presumably there is a lot of unmediated editor fighting, editors just overwrite each other rather than organize. Category {\it Military History of the US} is famous within Wikipedia for it's self-organizing task-forces, and exhibits $\beta = 0$. In fact it also only one of two Categories that ever have consecutive snapshots with $\beta < 0$. A possible interpretation is that because of the self-organization there is less edit-warring in this category, and each visit to the page by good editors has a definite, productive task at hand. Therefore we suggest that one can take $\beta$ as a "collaborativeness" metric, with a lower score meaning more collaborative.

Overall, it is amazing amazing that so little information (binary matrix $M_{ea}$ with information only on whether an editor as modified a given article) provided as an input to the algorithm is sufficient to achieve a high level of fidelity with actual metrics. It suggests some kind of {\it less is more} mechanism, which has implications on the computational aspects of the algorithm.



%From the Economics domain, ubiquity is seen as the "dis-quality" of a product. In Wikipedia that interpretation is more muddled. Some categories predicted best by high $\beta$, meaning that placing an emphasis on many editors touching an article is import to success. We chose "Category:Sexual acts" to see how a taboo category would fair. That articles and editors in "Category:Sexual acts"  achieve best success when many people edit is an unsurprising result then.
%
%Likewise we chose a Military history category, to inspect the performance  of the notoriously obsessive editors of "WikiProject:Military history". Here we find a maximizing $\beta = 0$, which means that editors and articles achieve no better success when they many people edit an article. That means that "single-handed" articles and editors are just as performant.

 


%$\mathbf{M}$ : most basic measure of collaboration, which represents the bi-partite network contributions to articles by editors: Here, we consider the simplest information available on collaboration: has an editor modified an article at any point in time or not ?


%Analyzing the Creative Editing Behavior of Wikipedia Editors: Through Dynamic Social Network Analysis \footnote{This paper analyzes editing patterns of Wikipedia contributors using dynamic social network analysis. We have developed a tool that converts the edit flow among contributors into a temporal social network. We are using this approach to identify the most creative Wikipedia editors among the few thousand contributors who make most of the edits amid the millions of active Wikipedia editors. In particular, we identify the key category of ÒcoolfarmersÓ, the prolific authors starting and building new articles of high quality. Towards this goal we analyzed the 2580 featured articles of the English Wikipedia where we found two main article types: (1) articles of narrow focus created by a few subject matter experts, and (2) articles about a broad topic created by thousands of interested incidental editors. We then investigated the authoring process of articles about a current and controversial event. There we found two types of editors with different editing patterns: the mediators, trying to reconcile the different viewpoints of editors, and the zealots, who are adding fuel to heated discussions on controversial topics. As a second category of editors we look at the ÒegoboostersÓ, people who use Wikipedia mostly to showcase themselves. Understanding these different patterns of behavior gives important insights about the cultural norms of online creators. In addition, identifying and policing egoboosters has the potential to increase the quality of Wikipedia. People best suited to enforce culture-compliant behavior of egoboosters through exemplary behavior and active intervention are the highly regarded coolfarmers introduced above. }\cite{iba2010}


%{\bf Network Analysis of Collaboration Structure in Wikipedia} \footnote{In this paper we give models and algorithms to describe and analyze the collaboration among authors of Wikipedia from a network analytical perspective. The edit network encodes who interacts how with whom when editing an article; it significantly extends previous network models that code author communities in Wikipedia. Several characteristics summarizing some aspects of the organization process and allowing the analyst to identify certain types of authors can be obtained from the edit network. Moreover, we propose several indicators characterizing the global network structure and methods to visualize edit networks. It is shown that the structural network indicators are correlated with quality labels of the associated Wikipedia articles.} \cite{brandes2009}


%The problem of ranking entities and their respective production is relevant to the flourishing production of knowledge on the Web, and is directly related to two outstanding problems, which have been previously debated. First, how do we gauge the quality (resp. reliability) of blog posts, book reviews (e.g., on Amazon), or restaurant reviews (e.g., on Yelp) ?  Second,  how to grant editing and administrative privileges on community networks (e.g., Slashdot) and on online collaborative platforms (e.g. Wikipedia) \cite{halfaker2013}. 
