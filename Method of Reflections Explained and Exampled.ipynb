{
 "metadata": {
  "name": "",
  "signature": "sha256:ec5d81d551dba0263be374c02960cb9e316b77de1f3dafdc4657ed51f117ccb3"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Method of reflections in python\n",
      "The Method of Reflection (MOR) is a algorithm first coming out of Macroeconomics, that ranks nodes in a bi-partite network. This notebook should hopefully help you implement the _method of reflection_ in python. To be precise, it is the modified algorithm that is proposed by Caldarelli et al., which solves some problems with the original Hidalgo-Hausmann (HH) algorithm [doi:10.1073/pnas.0900943106](http://chidalgo.com/Papers/HidalgoHausmann_PNAS_2009_PaperAndSM.pdf). The main problem with (HH) is that all values converge to a single fixed point after sufficiently many iterations. The Caldarelli version solves this by adding a new term to the recursive equation - what they call a _biased random walker_ (function _G_). [doi: 10.1371/journal.pone.0047278](http://www.plosone.org/article/info%3Adoi%2F10.1371%2Fjournal.pone.0047278). I hadn't seen any open-source implementations of this algorithm, so I thought I'd share my na\u00efve approach."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import datetime\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from collections import defaultdict\n",
      "import scipy.stats as ss\n",
      "from scipy.optimize import fmin as scipyfmin\n",
      "import operator\n",
      "import re\n",
      "import json\n",
      "\n",
      "#if you are using ipython and want to see things inline. \n",
      "%pylab inline "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Modelling the data\n",
      "We want to model a bi-partite network. Since we are using `numpy` and want to operate on a matrix we will use a `numpy.matrix`, but we also may want to retain the Unique IDs associated with each node, so we'll need to keep `dicts` of those as they relate to the matrix indices. Therefore for each bi-partite network at least __three files__ are needed. In my case I analysed a network which was a Wikipedia Category, so my two node-types are _users_ and _articles_. In your case they may be different, but I've kept the nomenclature here for simplicity - my own simplicity 8^). You can borrow my sample data from https://github.com/notconfusing/wiki_econ_capability/tree/master/savedata\n",
      "\n",
      "+ the `M.npy` - an numpy matrix _M_ - adjacently matrix of the network.\n",
      "+ `user_dict.json` - a mapping (json dictionary)between unique key (in my case Wikipedia user name) to _M_ row index.\n",
      "+ `article_dict` - a mapping (json dictionary) between unique key (in my case the name of the article) _M_ column index.\n",
      "\n",
      "##Extra data\n",
      "If you plan to calibrate your model against some exogenous metrics you will need to provide two more files - the rankings from the exogenous data.\n",
      "\n",
      "+ `user_exogenous_ranks.json` - a mapping (json dictionary) between the same keys of the  `user_dict` to their exogenous ranks (how well another metric ranks Wikipedia users).\n",
      "+ `article_exogenous_ranks.json` - a mapping (json dictionary) between the same keys of the  `article_dict` to their exogenous ranks (how well another metric ranks Wikipedia articles).\n",
      "\n",
      "##Putting it all in a folder\n",
      "I put everything belonging to one network into a single folder and then use this `load_files` method which unpacks all the object and gives you a dict of all the objects."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_files(folder):\n",
      "    M = np.load(folder+'M.npy')\n",
      "    user_dict = json.load(open(folder+'user_dict.json', 'r'))\n",
      "    article_dict = json.load(open(folder+'article_dict.json', 'r')) \n",
      "    user_exogenous_ranks = json.load(open(folder+'user_exogenous_ranks.json', 'r'))\n",
      "    article_exogenous_ranks = json.load(open(folder+'article_exogenous_ranks.json', 'r'))\n",
      "    return {'M':M,\n",
      "            'user_dict':user_dict,\n",
      "            'article_dict':article_dict,\n",
      "            'user_exogenous_ranks':user_exogenous_ranks, \n",
      "            'article_exogenous_ranks':article_exogenous_ranks}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "For instance, let's create the `feminist_data` dict, which holds data from _Category:Feminist_writers_ . I am snapshotting data, so that's why below you see two dates: when the snapshot was taken, and the latest date to be considered in the snapshot. So we are getting the full data from February 18th 2014."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "feminist_data = load_files('savedata/Category:Feminist_writers/2014-02-18/2014-02-18/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we define two operations on $M$. The _HH_ technique and those coming after use a binary input matrix, I also got better results, with a binary matrix. So we can normalise all our non-zero data to `1`. Also we may want to take a look at it an see if it has a triangular shape, since (MOR) assumes a triangular matrix."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_bin_matrix(M):\n",
      "    #this returns the a matrix with entry True where the original was nonzero, and zero otherwise.\n",
      "    M[M>0] = 1.0\n",
      "    return M\n",
      "\n",
      "def M_test_triangular(M):\n",
      "    user_edits_sum = M.sum(axis=1)\n",
      "    article_edits_sum = M.sum(axis=0)\n",
      "    \n",
      "    user_edits_order = user_edits_sum.argsort()\n",
      "    article_edits_order = article_edits_sum.argsort()\n",
      "    \n",
      "    M_sorted = M[user_edits_order,:]\n",
      "    M_sorted_sorted = M_sorted[:,article_edits_order]\n",
      "    \n",
      "    M_bin = make_bin_matrix(M_sorted_sorted)\n",
      "    \n",
      "    plt.figure(figsize=(10,10))\n",
      "    imshow(M_sorted_sorted, cmap=plt.cm.bone, interpolation='nearest')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bin_M = make_bin_matrix(feminist_data['M'])\n",
      "M_test_triangular(bin_M)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAIkAAAJPCAYAAABICvdJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7fd256573090>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok now let's move onto our third and fourth operations on $M$ - getting some numeric rankings out of the matrix. Let us refresh ourselves on the equations from the literature. (Note variables _c_ and _p_, countries and products, translate to editors and article respectively): \n",
      "\n",
      "##Zeroth order scores\n",
      "These are an $w_{c}$ editor-vector which is the sums of articles edited by each editor. Or the article-vector $w_{p}$, which is the sum of editors contributing to each article.\n",
      "\n",
      "\\begin{cases}\n",
      " w_{c}^{(0)} = \\sum_{p=1}^{N_{p}} M \\equiv k_c\\\\[7pt]\n",
      " w_{p}^{(0)} = \\sum_{c=1}^{N_{c}} M \\equiv k_p\n",
      "\\end{cases}\n",
      "\n",
      "## Higher orders\n",
      "The first order $w^{1}_c$ is the sum of the articles touched, but weighted by the Zeroth order article-vector (and the $G$ term). So if you've edited better articles that counts. And $w^{1}_c$ is the sum of editors touching, but weighted by the Zeroth order editor-vector (and $G$). So if you're touched by better editors that's also being considered. \n",
      "\n",
      "Beyond the first order interpretation for the higher orders is difficult.\n",
      "\n",
      "\\begin{cases}\n",
      "w^{(n+1)}_c (\\alpha,\\beta) = \\sum_{p=1}^{N_p}  G_{cp}(\\beta) \\,w^{(n)}_p (\\alpha,\\beta)\\\\[7pt]\n",
      "w^{(n+1)}_p (\\alpha,\\beta) = \\sum_{c=1}^{N_c}  G_{pc}(\\alpha) \\, w^{(n)}_c (\\alpha,\\beta)\\\\\n",
      "\\end{cases}\n",
      "\n",
      "## G - transition probability function\n",
      "Depending on $\\alpha$ and $\\beta$ we non-linearly weight based on the Zeroth order iterations. \n",
      "\n",
      "\\begin{cases}\n",
      "G_{cp}(\\beta) = \\frac{M_{cp} k_{c}^{-\\beta}}{\\sum_{c' = 1}^{N_c} M_{c'p} k_{c'}^{-\\beta}}\\\\[10pt]\n",
      "G_{pc}(\\alpha) = \\frac{M_{cp} k_{p}^{-\\alpha}}{\\sum_{p' = 1}^{N_p} M_{cp'} k_{p'}^{-\\alpha}}.\\\\\n",
      " \\end{cases}\n",
      "\n",
      "## Translating the mathematics into numpy\n",
      "And now we implement the mathematics in python. Hopefully I got this right, it hasn't been independently verified. Additionally I implement $w$ as a `generator`, so you can go on for many iterations without chewing up too much memory. There is also a stream function that allows you get a specific iteration. And lastly a `find_convergence` function, that checks to see if the rankings haven't shifted for two consecutive iterations."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def Gcp_denominateur(M, p, k_c, beta):\n",
      "    M_p = M[:,p]\n",
      "    k_c_beta = k_c ** (-1 * beta)\n",
      "    return np.dot(M_p, k_c_beta)\n",
      "\n",
      "def Gpc_denominateur(M, c, k_p, alpha):\n",
      "    M_c = M[c,:]\n",
      "    k_p_alpha = k_p ** (-1 * alpha)\n",
      "    return np.dot(M_c, k_p_alpha)\n",
      "\n",
      "\n",
      "def make_G_hat(M, alpha=1, beta=1):\n",
      "    '''G hat is Markov chain of length 2\n",
      "    Gcp is a matrix to go from  contries to product and then \n",
      "    Gpc is a matrix to go from products to ccountries'''\n",
      "    \n",
      "    k_c  = M.sum(axis=1) #aka k_c summing over the rows\n",
      "    k_p = M.sum(axis=0) #aka k_p summering over the columns\n",
      "    \n",
      "    G_cp = np.zeros(shape=M.shape)\n",
      "    #Gcp_beta\n",
      "    for [c, p], val in np.ndenumerate(M):\n",
      "        numerateur = (M[c,p]) * (k_c[c] ** ((-1) * beta))\n",
      "        denominateur = Gcp_denominateur(M, p, k_c, beta)\n",
      "        G_cp[c,p] = numerateur / float(denominateur)\n",
      "    \n",
      "    \n",
      "    G_pc = np.zeros(shape=M.T.shape)\n",
      "    #Gpc_alpha\n",
      "    for [p, c], val in np.ndenumerate(M.T):\n",
      "        numerateur = (M.T[p,c]) * (k_p[p] ** ((-1) * alpha))\n",
      "        denominateur = Gpc_denominateur(M, c, k_p, alpha)\n",
      "        G_pc[p,c] = numerateur / float(denominateur)\n",
      "    \n",
      "    \n",
      "    return {'G_cp': G_cp, \"G_pc\" : G_pc}\n",
      "\n",
      "def w_generator(M, alpha, beta):\n",
      "    #this cannot return the zeroeth iteration\n",
      "    \n",
      "    G_hat = make_G_hat(M, alpha, beta)\n",
      "    G_cp = G_hat['G_cp']\n",
      "    G_pc = G_hat['G_pc']\n",
      "    #\n",
      "\n",
      "    fitness_0  = np.sum(M,1)\n",
      "    ubiquity_0 = np.sum(M,0)\n",
      "    \n",
      "    fitness_next = fitness_0\n",
      "    ubiquity_next = ubiquity_0\n",
      "    i = 0\n",
      "    \n",
      "    while True:\n",
      "        \n",
      "        fitness_prev = fitness_next\n",
      "        ubiquity_prev = ubiquity_next\n",
      "        i += 1\n",
      "        \n",
      "        fitness_next = np.sum( G_cp*ubiquity_prev, axis=1 )\n",
      "        ubiquity_next = np.sum( G_pc* fitness_prev, axis=1 )\n",
      "        \n",
      "        yield {'iteration':i, 'fitness': fitness_next, 'ubiquity': ubiquity_next}\n",
      "        \n",
      "\n",
      "\n",
      "def w_stream(M, i, alpha, beta):\n",
      "    \"\"\"gets the i'th iteration of reflections of M, \n",
      "    but in a memory safe way so we can calculate many generations\"\"\"\n",
      "    if i < 0:\n",
      "        raise ValueError\n",
      "    for j in w_generator(M, alpha, beta):\n",
      "        if j[0] == i:\n",
      "            return {'fitness': j[1], 'ubiquity': j[2]}\n",
      "            break\n",
      "            \n",
      "def find_convergence(M, alpha, beta, fit_or_ubiq, do_plot=False,):\n",
      "    '''finds the convergence point (or gives up after 1000 iterations)'''\n",
      "    if fit_or_ubiq == 'fitness':\n",
      "        Mshape = M.shape[0]\n",
      "    elif fit_or_ubiq == 'ubiquity':\n",
      "        Mshape = M.shape[1]\n",
      "    \n",
      "    rankings = list()\n",
      "    scores = list()\n",
      "    \n",
      "    prev_rankdata = np.zeros(Mshape)\n",
      "    iteration = 0\n",
      "\n",
      "    for stream_data in w_generator(M, alpha, beta):\n",
      "        iteration = stream_data['iteration']\n",
      "        \n",
      "        data = stream_data[fit_or_ubiq]\n",
      "        rankdata = data.argsort().argsort()\n",
      "        \n",
      "        #test for convergence\n",
      "        if np.equal(rankdata,prev_rankdata).all():\n",
      "            break\n",
      "        if iteration == 1000:\n",
      "            break\n",
      "        else:\n",
      "            rankings.append(rankdata)\n",
      "            scores.append(data)\n",
      "            prev_rankdata = rankdata\n",
      "            \n",
      "    if do_plot:\n",
      "        plt.figure(figsize=(iteration/10, Mshape / 20))\n",
      "        plt.xlabel('Iteration')\n",
      "        plt.ylabel('Rank, higher is better')\n",
      "        plt.title('Rank Evolution')\n",
      "        p = semilogx(range(1,iteration), rankings, '-,', alpha=0.5)\n",
      "    return {fit_or_ubiq:scores[-1], 'iteration':iteration}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We also know from Caldarelli et al. that there is an analytic formulation to the recursive procedure. So if you want to save some (a lot) processing and just know the end result we can use:\n",
      "\n",
      "## Analytic solution\n",
      "\n",
      "\\begin{cases}\n",
      "w^{*}_e (\\alpha,\\beta) = (\\sum_{a=1}^{N_a} M_{ea}k_{a}^{-\\alpha})k_{e}^{-\\beta} \\\\\n",
      "w^{*}_a (\\alpha,\\beta) = (\\sum_{e=1}^{N_e}  M_{ea}k_{e}^{-\\beta})k_{a}^{-\\alpha}\\\\\n",
      "\\end{cases}\n",
      "\n",
      "And again in python:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def w_star_analytic(M, alpha, beta, w_star_type):\n",
      "    k_c  = M.sum(axis=1) #aka k_c summing over the rows\n",
      "    k_p = M.sum(axis=0) #aka k_p summering over the columns\n",
      "    \n",
      "    A = 1\n",
      "    B = 1\n",
      "    \n",
      "    def Gcp_denominateur(M, p, k_c, beta):\n",
      "        M_p = M[:,p]\n",
      "        k_c_beta = k_c ** (-1 * beta)\n",
      "        return np.dot(M_p, k_c_beta)\n",
      "    \n",
      "    def Gpc_denominateur(M, c, k_p, alpha):\n",
      "        M_c = M[c,:]\n",
      "        k_p_alpha = k_p ** (-1 * alpha)\n",
      "        return np.dot(M_c, k_p_alpha)\n",
      "    \n",
      "    if w_star_type == 'w_star_c':\n",
      "        w_star_c = np.zeros(shape=M.shape[0])\n",
      "\n",
      "        for c in range(M.shape[0]):\n",
      "            summand = Gpc_denominateur(M, c, k_p, alpha)\n",
      "            k_beta = (k_c[c] ** (-1 * beta))\n",
      "            w_star_c[c] = A * summand * k_beta\n",
      "\n",
      "        return w_star_c\n",
      "    \n",
      "    elif w_star_type == 'w_star_p':\n",
      "        w_star_p = np.zeros(shape=M.shape[1])\n",
      "    \n",
      "        for p in range(M.shape[1]):\n",
      "            summand = Gcp_denominateur(M, p, k_c, beta)\n",
      "            k_alpha = (k_p[p] ** (-1 * alpha))\n",
      "            w_star_p[p] = B * summand * k_alpha\n",
      "    \n",
      "        return w_star_p"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Running the iterative and analytic solutions on data.\n",
      "We will run our algorithms on our data. The output of both the iterative and the analytic solutions are a list of scores. So in order to know who was the best, we afterwards identify (this is why we need the ID-mapping) and sort the identified list. I use `pandas` here to simply life, but I've also done it in pure-python if you're not familiar with `pandas`. Also I arbitrarily use $(\\alpha, \\beta) = (0,0)$.\n",
      "\n",
      "###First lets use the analytic solution."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#purer python\n",
      "#score\n",
      "w_scores = w_star_analytic(M=feminist_data['M'], alpha=0.5, beta=0.5, w_star_type='w_star_c')\n",
      "#identify\n",
      "w_ranks = {name: w_scores[pos] for name, pos in feminist_data['user_dict'].iteritems() }\n",
      "#sort\n",
      "w_ranks_sorted = sorted(w_ranks.iteritems(), key=operator.itemgetter(1))\n",
      "\n",
      "#or use pandas\n",
      "w_scores_df = pd.DataFrame.from_dict(w_ranks, orient='index')\n",
      "w_scores_df.columns = ['w_score']\n",
      "w_scores_df.sort(columns=['w_score'], ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>w_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Dsp13</th>\n",
        "      <td> 2.230387</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Bearcat</th>\n",
        "      <td> 2.107264</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Johnpacklambert</th>\n",
        "      <td> 2.047463</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Solar-Wind</th>\n",
        "      <td> 1.952138</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Treybien</th>\n",
        "      <td> 1.850515</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "                  w_score\n",
        "Dsp13            2.230387\n",
        "Bearcat          2.107264\n",
        "Johnpacklambert  2.047463\n",
        "Solar-Wind       1.952138\n",
        "Treybien         1.850515\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well done users _Dsp13_ and _Bearcat_. If you look up these user's on English Wikipedia, you can see at a glance they are accomplished editors - so this is also a good sanity check. (Isn't there a Mogwai video called _Bearcat_? Oh, no it's [Batcat](https://www.youtube.com/watch?v=KMDCM5OAOaE) \\\\m/ never mind let's move on.) \n",
      "\n",
      "##Verification with the iterative method.\n",
      "Let's take the long way home, and check that the shortcut actually takes us to the right place. We use the iterative method with the same data, until we find convergence. Also I make a plot here of the ranks of the users after each iteration, so we can track them. So each line you see is the history of user's rise to Glory, or their slow decline to forgotten irrelevance (or none of those phenomenon). Actually if you see a user going up its because the value of the articles edited is increasing. And likewise if a user is losing standing, its because they edited a lot of articles, but were of poor quality."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "convergence = find_convergence(M=feminist_data['M'], alpha=0.5, beta=0.5, fit_or_ubiq='fitness', do_plot=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "convergence['iteration']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "661"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It looks like it took 661 iterations for this particular network to converge with $(\\alpha, \\beta) = (0,0)$. Now, let's what the ranking produce."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "w_iter = convergence['fitness'] \n",
      "#rank\n",
      "w_iter_ranks = {name: w_iter[pos] for name, pos in feminist_data['user_dict'].iteritems() }\n",
      "#sort\n",
      "w_ranks_sorted = sorted(w_iter_ranks.iteritems(), key=operator.itemgetter(1))\n",
      "\n",
      "#or use pandas\n",
      "w_iter_scores_df = pd.DataFrame.from_dict(w_iter_ranks, orient='index')\n",
      "w_iter_scores_df.columns = ['w_score']\n",
      "w_iter_scores_df.sort(columns=['w_score'], ascending=False).head()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>w_score</th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>Dsp13</th>\n",
        "      <td> 30.640203</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Bearcat</th>\n",
        "      <td> 28.948788</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Johnpacklambert</th>\n",
        "      <td> 28.127272</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Solar-Wind</th>\n",
        "      <td> 26.817729</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>Treybien</th>\n",
        "      <td> 25.421677</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 1 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 47,
       "text": [
        "                   w_score\n",
        "Dsp13            30.640203\n",
        "Bearcat          28.948788\n",
        "Johnpacklambert  28.127272\n",
        "Solar-Wind       26.817729\n",
        "Treybien         25.421677\n",
        "\n",
        "[5 rows x 1 columns]"
       ]
      }
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Verified. You can see the analytic and iterative methods produce the same ranking, but the scores are off by a normalisation constant.\n",
      "\n",
      "## Calibration with exogenous variables.\n",
      "\n",
      "Lastly, we might want to know what values of $alpha$ and $beta$ maximise our correlation between model and actual. Without resorting to any fancy optimisers, let's just perform a grid-search. With a grid-serch we can also get a picture of the landscape. We define a way to compare our list rankings using the Spearman method from `scipy.stats`. Then we'll make a landscape of $[-2,2] \\times [-2,2]$ with resolution $50 \\times 50$, and evaluate at all those points (using the analytic method). Finally we will return the top correlation we found."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''I'm sure this can be done much more elegantly\n",
      "but this was sort-of drink-a-lot-of-coffee-one-afternoon-and-get-it-done\n",
      "cleaning this up is an exercise for the reader'''\n",
      "\n",
      "def rank_comparison(a_ranks_sorted, b_ranks_sorted, do_plot=False):\n",
      "    a_list = list()\n",
      "    b_list = list()\n",
      "    for atup in a_ranks_sorted:\n",
      "        aiden = atup[0]\n",
      "        apos = atup[1]\n",
      "        #find this in our other list\n",
      "        for btup in b_ranks_sorted:\n",
      "            biden = btup[0]\n",
      "            bpos = btup[1]\n",
      "            if aiden == biden:\n",
      "                a_list.append(apos)\n",
      "                b_list.append(bpos)\n",
      "    if do_plot:    \n",
      "        plt.figure(figsize=(10,20))\n",
      "        plot([1,2], [a_list, b_list], '-o')\n",
      "        plt.show()\n",
      "    \n",
      "    return ss.spearmanr(a_list, b_list)\n",
      "\n",
      "def calibrate_analytic(M, ua, exogenous_ranks_sorted, user_or_art_dict, index_function, title, do_plot=False):\n",
      "    \n",
      "    if ua == 'users':\n",
      "        w_star_type = 'w_star_c'\n",
      "    elif ua == 'articles':\n",
      "        w_star_type = 'w_star_p'\n",
      "    \n",
      "    squarelen = range(0,50)\n",
      "    \n",
      "    alpha_range = map(index_function,squarelen)\n",
      "    beta_range = map(index_function,squarelen)\n",
      "    landscape = np.zeros(shape=(len(list(alpha_range)),len(list(beta_range))))\n",
      "\n",
      "    top_spearman = {'spearman':None,'alpha':None, 'beta':None, 'ua':ua}\n",
      "\n",
      "    for alpha_index, alpha in enumerate(alpha_range):\n",
      "        for beta_index, beta in enumerate(beta_range):\n",
      "            \n",
      "            w_converged = w_star_analytic(M, alpha, beta, w_star_type)\n",
      "            \n",
      "            w_ranks = {name: w_converged[pos] for name, pos in user_or_art_dict.iteritems() }\n",
      "            w_ranks_sorted = sorted(w_ranks.iteritems(), key=operator.itemgetter(1))\n",
      "            \n",
      "            spearman = rank_comparison(w_ranks_sorted, exogenous_ranks_sorted)\n",
      "\n",
      "            if spearman[1] < 0.05:\n",
      "                landscape[alpha_index][beta_index] = spearman[0]\n",
      "                \n",
      "                if (not top_spearman['spearman']) or (spearman[0] > top_spearman['spearman']):\n",
      "                    top_spearman['spearman'] = spearman[0]\n",
      "                    top_spearman['alpha'] = alpha\n",
      "                    top_spearman['beta'] = beta\n",
      "            else:\n",
      "                landscape[alpha_index][beta_index] = np.nan\n",
      "\n",
      "    if do_plot:\n",
      "        plt.figure(figsize=(10,10))\n",
      "        heatmap = imshow(landscape, interpolation='nearest', vmin=-1, vmax=1)\n",
      "        #heatmap = plt.pcolor(landscape)\n",
      "        colorbar = plt.colorbar(heatmap)\n",
      "        plt.xlabel(r'$ \\beta $')\n",
      "        plt.xticks(squarelen, beta_range, rotation=90)\n",
      "        plt.ylabel(r'$ \\alpha $')\n",
      "        plt.yticks(squarelen, alpha_range)\n",
      "        plt.title(title)\n",
      "        \n",
      "        landscape_file = open(title+'_landscape.npy', 'w')\n",
      "        np.save(landscape_file, landscape)\n",
      "        plt.savefig(title+'_landscape.eps')\n",
      "\n",
      "    return top_spearman"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 67
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now let's run the calibration and get our optimising variables."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "user_spearman = calibrate_analytic(M=make_bin_matrix(feminist_data['M']),\n",
      "                                   ua='users',\n",
      "                                   exogenous_ranks_sorted=feminist_data['user_exogenous_ranks'],\n",
      "                                   user_or_art_dict=feminist_data['user_dict'],\n",
      "                                   index_function=lambda x: (x-25)/12.5, \n",
      "                                   title='Grid Search for User of Feminist Writers',\n",
      "                                   do_plot=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Note that the white parts of the gridsearch are where the Spearman rho value was not significant using 0.05 as a threshold."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('Optimizing points from gridsearch', \n",
      "      'rho:', user_spearman['spearman'], \n",
      "      'alpha', user_spearman['alpha'], \n",
      "      'beta', user_spearman['beta'] )"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "('Optimizing points from gridsearch', 'rho:', 0.6923148495709821, 'alpha', 0.0, 'beta', -2.0)\n"
       ]
      }
     ],
     "prompt_number": 60
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well it looks like this optimising point occurs on the boundary. But we can see also that $\\{\\alpha, \\beta |\\alpha = 0, \\beta < 1\\}$ seems to be an optimising solution set ripe for further investigation. \n",
      "\n",
      "#Conclusion\n",
      "I hope this allows you to see how Method of Reflections works, and - importantly - how to translate it into different domains. Anywhere you have a bi-partite network you can start ranking nodes using this technique! And if you have some exogenous data, you can also calibrate your model. Please alert me if there are any mistakes in here.\n",
      "\n",
      "##License\n",
      "\n",
      "The MIT License (MIT)\n",
      "\n",
      "Copyright \u00a9 2014 Max Klein aka notconfusing\u203d\n",
      "\n",
      "Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
      "\n",
      "The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\n",
      "\n",
      "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}