{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pywikibot\n",
      "from pywikibot import pagegenerators\n",
      "import datetime\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from collections import defaultdict\n",
      "import datetime\n",
      "import scipy.stats as ss\n",
      "import operator\n",
      "import os\n",
      "%pylab inline\n",
      "\n",
      "\n",
      "enwp, dewp, frwp = (pywikibot.Site(lang, 'wikipedia') for lang in ['en', 'de', 'fr'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n"
       ]
      }
     ],
     "prompt_number": 212
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if not enwp.logged_in: enwp.login()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_arts(category_name, wp=enwp):\n",
      "\n",
      "    if category_name:\n",
      "        cat = pywikibot.Category(wp, category_name)\n",
      "        articles = list(cat.articles())\n",
      "        save_name = category_name\n",
      "    \n",
      "    load_article_revisions(articles, wp)\n",
      "\n",
      "    return articles"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_rev_dict(article):\n",
      "    revdict = {rev.timestamp : {'user' : rev.user, 'article' : article.title()} for rev in article._revisions.itervalues()}\n",
      "    return revdict\n",
      "\n",
      "def make_revision_df(article_list):\n",
      "    all_revisions = pd.DataFrame(columns=['user', 'article'], index=pd.TimeSeries())\n",
      "    \n",
      "    for article in article_list:\n",
      "        all_revisions = all_revisions.append(pd.DataFrame.from_dict(data=make_rev_dict(article), orient='index'))\n",
      "        \n",
      "    return all_revisions"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 78
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_snapshots(name, all_revisions_df, periods=10, remove_minimum=20):\n",
      "    '''returns a dict period snapshots as determined by number of edits\n",
      "    made by users contributing at least remove_minium edits'''\n",
      "    snapshots = dict()\n",
      "    \n",
      "    user_ar = all_revisions_df.groupby(by='user')\n",
      "    edit_sizes = user_ar.size()\n",
      "    min_editors = edit_sizes[ edit_sizes > 10]\n",
      "    criterion = all_revisions_df['user'].map(lambda user: user in min_editors.index)\n",
      "    min_revisions = all_revisions_df[criterion]\n",
      "    \n",
      "    sorted_min_revisions = min_revisions.sort(axis=0)\n",
      "    \n",
      "    period_len = len(min_revisions)/float(periods)\n",
      "    \n",
      "    for i in range(1, periods+1):\n",
      "        start = 0\n",
      "        end = int(floor(i*period_len))\n",
      "        \n",
      "        print  sorted_min_revisions[start:end].last_valid_index()\n",
      "        snapshots[i] = sorted_min_revisions[start:end]\n",
      "        \n",
      "    for i, df in snapshots.iteritems():\n",
      "        directory = name\n",
      "        today = str(datetime.date.today())\n",
      "        double_directory = directory + '/' + today + '/'\n",
      "        \n",
      "        if not os.path.exists(double_directory):\n",
      "            os.makedirs(double_directory)\n",
      "        filename = double_directory  + str(i) + '.json'\n",
      "        f = open(filename, 'w')\n",
      "        \n",
      "        snapshots[i].to_json(f)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_to_matrix(pandas_json_file):\n",
      "    df = pd.read_json(pandas_json_file)\n",
      "    u_grouped = df.groupby('user')\n",
      "    a_grouped = df.groupby('article')\n",
      "    ua_grouped = df.groupby(by = ['user', 'article'])\n",
      "    \n",
      "    '''these dicts are so we can back translate the indexes in the matrix to real users and articles'''\n",
      "    users = list(u_grouped.groups.iterkeys())\n",
      "    articles = list(a_grouped.groups.iterkeys())\n",
      "    user_dict = {username: users.index(username) for username in users}\n",
      "    article_dict = {articlename: articles.index(articlename) for articlename in articles}\n",
      "    \n",
      "    contributor_matrix = np.zeros(shape=(len(users), len(articles)))\n",
      "    \n",
      "    for user_article_tuple, timestamps in ua_grouped.groups.iteritems():\n",
      "        user_string = user_article_tuple[0]\n",
      "        article_string = user_article_tuple[1]\n",
      "        user_index = user_dict[user_string]\n",
      "        article_index = article_dict[article_string]\n",
      "        \n",
      "        contributor_matrix[user_index][article_index] = len(timestamps)\n",
      "        \n",
      "    return contributor_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 301
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pjf = 'fem/2014-01-29/5.json'\n",
      "M = load_to_matrix(pjf)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 302,
       "text": [
        "array([[ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       ..., \n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0., ...,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 302
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.rank(M.sum(axis=0)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 311,
       "text": [
        "1"
       ]
      }
     ],
     "prompt_number": 311
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M.sort(axis=0, order=M.sum(axis=0))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "ValueError",
       "evalue": "Cannot specify order when the array has no fields.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-309-4d06d03063e2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mValueError\u001b[0m: Cannot specify order when the array has no fields."
       ]
      }
     ],
     "prompt_number": 309
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i in range(1,11):\n",
      "    pjf = 'fem/2014-01-29/'+str(i)+'.json'\n",
      "    mar = load_to_matrix(pjf)\n",
      "    print mar.last_valid_index()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "2006-06-04 06:58:57\n",
        "2007-01-29 02:17:08\n",
        "2007-09-16 11:09:53"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2008-04-28 21:38:26\n",
        "2009-04-12 23:37:47"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2010-04-09 20:00:09"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2011-03-28 23:44:25"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2012-05-24 23:02:19"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2013-03-05 18:14:14"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "2014-01-29 16:07:09"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_cum_edit_series(all_revisions_df):\n",
      "    '''ar should be an all_revisions dataframe like one made by make_revision_df'''\n",
      "    ar == all_revisons_df\n",
      "    ar['row'] = 1\n",
      "    ar['edits'] = cumsum(ar['row'])\n",
      "    edits = ar['edits']\n",
      "    return edits"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_rev_dict(article):\n",
      "    revdict = {rev.timestamp : {'user' : rev.user, 'article' : article.title()} for rev in article._revisions.itervalues()}\n",
      "    return revdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 60
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_contributor_matrix(category_name=None, outlinks_page_name=None, as_df=False, wp=enwp):\n",
      "\n",
      "    if category_name:\n",
      "        cat = pywikibot.Category(wp, category_name)\n",
      "        articles = list(cat.articles())\n",
      "        save_name = category_name\n",
      "    if outlinks_page_name:\n",
      "        outlinks = pagegenerators.LinkedPageGenerator(pywikibot.Page(wp, outlinks_page_name))\n",
      "        articles = filter(lambda page: page.namespace() == 0, outlinks)\n",
      "        save_name = outlinks_page_name\n",
      "    \n",
      "    load_article_revisions(articles, wp)\n",
      "\n",
      "    contributor_df = make_dataframe(articles)\n",
      "    \n",
      "    save_name = save_name.replace('/', '___')\n",
      "    filename = 'savedata/' + save_name + unicode(datetime.datetime.now())\n",
      "    \n",
      "    minimum_edits_df = minimum_edits(contributor_df)\n",
      "    \n",
      "    minimum_matrix = minimum_edits_df.as_matrix()\n",
      "    \n",
      "    np.save(filename, minimum_matrix)\n",
      "    \n",
      "    if as_df:\n",
      "        return minimum_edits_df\n",
      "    else:\n",
      "        return minimum_matrix"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_article_revisions(articles, wp):\n",
      "    def earliest_revision(article):\n",
      "        revisions  = list(article._revisions.itervalues())\n",
      "        timestamps = map(lambda r: r.timestamp, revisions)\n",
      "        earliest = min(timestamps)\n",
      "        return earliest\n",
      "    \n",
      "    def load_all_revisions(article, wp):\n",
      "        before_count = len(article._revisions)\n",
      "        #print \"before \", before_count\n",
      "        if before_count == 0:\n",
      "            article.getVersionHistory()\n",
      "        else:\n",
      "            wp.loadrevisions(page=article, starttime=earliest_revision(article))\n",
      "        after_count = len(article._revisions)\n",
      "        #print \"after \", after_count\n",
      "        if before_count == after_count:\n",
      "            return\n",
      "        else:\n",
      "            load_all_revisions(article, wp)\n",
      "        \n",
      "    map(lambda article: load_all_revisions(article, wp), articles)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_dict_contributors(articles):\n",
      "    def contributors_articles_dict():\n",
      "        return defaultdict(int)\n",
      "    \n",
      "    contributors = defaultdict(contributors_articles_dict)\n",
      "    filtered_contributors = defaultdict(contributors_articles_dict)\n",
      "    \n",
      "    for article in articles:\n",
      "        for revid, revision_obj in article._revisions.iteritems():\n",
      "            user = revision_obj.user\n",
      "            contributors[user][article] += 1\n",
      "    \n",
      "            \n",
      "    for user, article_dict in contributors.iteritems():\n",
      "        for article, count in article_dict.iteritems():\n",
      "            if user:\n",
      "                if article:\n",
      "                    if count:\n",
      "                        filtered_contributors[user][article] = count\n",
      "                            \n",
      "    #print contributors == filtered_contributors\n",
      "            \n",
      "    return filtered_contributors"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_dataframe(articles):\n",
      "    contributor_dict = make_dict_contributors(articles)\n",
      "    contributor_df = pd.DataFrame.from_dict(data = contributor_dict, orient='index')\n",
      "    contributor_df = contributor_df.fillna(value=0)\n",
      "    contributor_df = contributor_df.convert_objects(convert_numeric=True)\n",
      "    \n",
      "    return contributor_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def minimum_edits(contributor_df, minimum=25):\n",
      "    mrows = contributor_df[contributor_df.apply(lambda row: any(row > 25), axis=1)]\n",
      "    #and now we have to clean to columns which are articles that no one contributed to in our remaining group\n",
      "    minimum_edits_df = mrows.loc[:,mrows.apply(lambda col: any(col > 0), axis=0)]\n",
      "    return minimum_edits_df"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fems = load_arts(category_name='Category:Feminist_writers') "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    }
   ],
   "metadata": {}
  }
 ]
}